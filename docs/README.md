# SubTranslate - 智能视频字幕翻译系统

## 项目概述

SubTranslate是一个自动化视频字幕提取、翻译和整合系统，旨在为视频创作者和观看者提供高质量的多语言字幕支持。系统能够从各种视频格式中提取字幕，借助AI进行智能翻译，并将翻译后的字幕与原视频关联，提升跨语言视频内容的可访问性和用户体验。

## 需求详细规划

### 1. 系统架构

本项目采用前后端分离架构：
- **前端**：基于React的Web应用，提供用户友好的操作界面
- **后端**：Python FastAPI应用，处理核心业务逻辑
- **数据存储**：本地文件系统存储，用于管理视频和字幕文件
- **AI集成**：通过API与GPT模型集成，实现字幕智能翻译

### 2. 功能模块

#### 2.1 视频字幕提取模块

**功能描述**：
- 支持多种视频格式（包括但不限于MKV、MP4）的字幕提取
- 提取内嵌字幕轨道并转换为SRT格式
- 对无字幕视频提供语音识别生成字幕功能（可选功能）
- 支持批量处理多个视频文件

**技术方案**：
- 使用FFmpeg作为底层视频处理引擎
- 集成pysrt库处理SRT文件格式
- 可选集成whisper-api进行语音识别（无字幕情况）

**性能要求**：
- 处理1小时视频的字幕提取时间不超过3分钟
- 支持多线程并行处理多个视频文件

#### 2.2 字幕翻译模块

**功能描述**：
- 将SRT格式字幕文件内容发送至GPT进行翻译
- 支持字幕分块处理，避免超出API限制
- 保持原字幕的时间轴和格式信息不变
- 智能处理文化差异和上下文连贯性

**技术方案**：
- 集成OpenAI API或其他大语言模型API
- 开发针对字幕翻译优化的prompt系统
- 实现字幕上下文记忆机制，保持翻译一致性

**翻译质量要求**：
- 保持对话自然流畅
- 正确翻译专业术语
- 保持人物语气和风格一致
- 适当本地化文化表达

#### 2.3 字幕整合输出模块

**功能描述**：
- 将翻译后的字幕保存为新的SRT文件
- 自动命名并存放在原视频所在目录
- 可选支持字幕嵌入视频（创建新视频文件）功能
- 支持多语言字幕生成（扩展功能）

**技术方案**：
- 使用pysrt库处理SRT文件写入
- 可选使用FFmpeg进行字幕硬编码到视频

**输出要求**：
- 保持与原字幕一致的时间戳
- 支持UTF-8编码确保多语言兼容性
- 文件命名遵循"原文件名.zh.srt"格式

#### 2.4 用户界面模块

**功能描述**：
- 提供直观的拖放视频上传界面
- 显示处理进度和状态
- 支持批量任务管理
- 提供翻译设置和定制选项

**技术方案**：
- 使用React构建响应式Web界面
- WebSocket实现实时进度更新
- 支持深色/浅色主题

**用户体验要求**：
- 操作步骤不超过3步完成主要功能
- 提供清晰的错误提示和故障恢复机制
- 支持键盘快捷操作

### 3. 核心流程

1. **输入阶段**
   - 用户上传视频文件或指定本地视频路径
   - 系统检测视频格式和字幕情况
   - 用户设置翻译参数（目标语言、翻译风格等）

2. **处理阶段**
   - 系统提取视频中的字幕轨道或外挂字幕
   - 如无字幕，可选启动语音识别生成原文字幕
   - 将字幕分段处理并发送至GPT进行翻译
   - 系统整合翻译结果，保持时间轴对齐

3. **输出阶段**
   - 生成翻译后的SRT文件
   - 保存至原视频所在目录
   - 提供字幕预览和编辑功能（可选）
   - 生成处理报告

### 4. 技术栈选择

**前端**：
- React.js + TypeScript
- Chakra UI / Ant Design组件库
- Redux状态管理
- Axios进行API通信

**后端**：
- Python 3.10+
- FastAPI Web框架
- Pydantic数据验证
- FFmpeg视频处理
- pysrt字幕处理
- OpenAI API集成

**部署**：
- Docker容器化
- 支持本地部署和云服务部署

### 5. 数据结构设计

**视频信息模型**：
```
VideoInfo {
    id: string
    filename: string
    path: string
    duration: number
    hasEmbeddedSubtitle: boolean
    format: string
    status: ProcessingStatus
    createdAt: datetime
}
```

**字幕处理任务模型**：
```
SubtitleTask {
    id: string
    videoId: string
    sourceLanguage: string
    targetLanguage: string
    status: TaskStatus
    progress: number
    sourcePath: string
    resultPath: string
    createdAt: datetime
    completedAt: datetime
    errorMessage: string
}
```

**翻译配置模型**：
```
TranslationConfig {
    style: TranslationStyle
    preserveFormatting: boolean
    handleCulturalReferences: boolean
    glossary: Map<string, string>
    contextPreservation: boolean
}
```

### 6. 非功能需求

**性能需求**：
- 支持并发处理多个视频文件
- 处理1小时视频的完整流程不超过10分钟
- 支持大文件处理（>4GB视频文件）

**安全需求**：
- 本地处理个人视频，确保隐私
- 仅发送字幕文本至AI API，不传输视频内容
- 支持用户自定义API密钥

**扩展性需求**：
- 支持插件系统扩展更多视频和字幕格式
- 支持添加更多翻译服务提供商
- 预留多语言翻译扩展接口

**兼容性需求**：
- 支持Windows、macOS和Linux系统
- 支持主流浏览器访问Web界面
- 兼容常见的视频播放器字幕格式

### 7. 项目规划

**第一阶段（MVP）**：
- 实现核心字幕提取功能
- 实现基础GPT翻译功能
- 开发简单的命令行界面
- 支持MP4和MKV格式

**第二阶段**：
- 开发Web用户界面
- 增强翻译质量和上下文处理
- 添加批量处理功能
- 支持更多视频格式

**第三阶段**：
- 优化用户体验
- 添加字幕编辑功能
- 支持多语言翻译
- 实现系统部署包

**第四阶段（扩展）**：
- 添加高级定制化选项
- 支持语音识别生成字幕
- 开发桌面客户端
- 支持云端部署

### 8. 成功指标

- **功能完整性**：成功提取、翻译和输出90%以上常见视频格式的字幕
- **翻译质量**：80%以上的用户认为翻译质量优于机器翻译
- **性能效率**：比人工翻译流程提高10倍以上的效率
- **用户体验**：操作简单度评分达到4.5/5以上

## 技术实现注意事项

1. 使用Python的Schema驱动开发方法，确保数据模型清晰
2. 采用src布局规范组织代码结构
3. 使用强类型提示增强代码可维护性
4. 实现完善的错误处理机制，特别是针对各种异常视频格式
5. 开发详细的API文档，方便前后端协作
6. 使用UV进行依赖管理，确保环境一致性

## 后续发展方向

1. 添加字幕风格转换功能（如将正式语言转为口语化）
2. 支持自定义翻译规则和专业领域字幕处理
3. 开发视频内容摘要生成功能
4. 添加字幕质量评估和自动校正功能
5. 实现云端处理服务，支持移动设备远程提交任务

---

本文档将随项目发展持续更新。如有问题或建议，请提交Issue讨论。 